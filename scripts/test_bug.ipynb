{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fc714389220>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from common import get_cfg, prepare_val\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATASET_DIR = '/media/hcis-s20/SRL/nuscenes/trainval/'\n",
    "vehicle_idx = [4, 5, 6, 7, 8, 10, 11,12]\n",
    "DYNAMIC = [\n",
    "    'car', 'truck', 'bus',\n",
    "    'trailer', 'construction_vehicle',\n",
    "    'pedestrian',\n",
    "    'motorcycle', 'bicycle',\n",
    "    # 'emergency',\n",
    "]\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hcis-s20/SRL/cross_view_ae/cross_view_transformers/scripts/common.py:50: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path='../config')\n",
      "/media/hcis-s20/SRL/cross_view_ae/cross_view_transformers/scripts/common.py:14: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path='./config')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Dataset length: 6019\n"
     ]
    }
   ],
   "source": [
    "version = 'cvt_labels_nuscenes_v2'\n",
    "cfg1 = get_cfg(DATASET_DIR, version, 'SparseBEVSeg_Det_3') # cvt_nuscenes_multiclass Sparse\n",
    "device = torch.device('cuda:0') # cuda:5\n",
    "model_version = '2024_0826_180130'\n",
    "CHECKPOINT_PATH = None\n",
    "# CHECKPOINT_PATH = '../logs/cross_view_transformers_test/' + model_version +'/checkpoints/last.ckpt'\n",
    "model, network, loader, viz, dataset = prepare_val(cfg1, device, CHECKPOINT_PATH, mode='val', batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    }
   ],
   "source": [
    "network.to(device)\n",
    "model.to(device)\n",
    "model.metrics.reset()\n",
    "with_grad = True\n",
    "\n",
    "if with_grad:\n",
    "    network.train()\n",
    "    # with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        if i != 0:\n",
    "            continue\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(device)\n",
    "            elif isinstance(v, list):\n",
    "                if isinstance(v[0], torch.Tensor):\n",
    "                    batch[k] = [i.to(device) for i in v]\n",
    "            else:\n",
    "                batch[k] = v\n",
    "        pred = network(batch)\n",
    "        loss = model.loss_func(pred,batch)\n",
    "        loss[0].backward()\n",
    "        vis_result = viz(batch,pred)\n",
    "        break\n",
    "else:\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(loader):\n",
    "            print(i,end='\\r')\n",
    "            for k, v in batch.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    batch[k] = v.to(device)\n",
    "                elif isinstance(v, list):\n",
    "                    if isinstance(v[0], torch.Tensor):\n",
    "                        batch[k] = [i.to(device) for i in v]\n",
    "                else:\n",
    "                    batch[k] = v\n",
    "            pred = network(batch)\n",
    "            # pred['mid_output']['sampled_feats'].retain_grad()\n",
    "            loss = model.loss_func(pred,batch)\n",
    "            # loss[0].backward()\n",
    "            vis_result = viz(batch,pred)\n",
    "    # if i ==5:\n",
    "            break   \n",
    "        \n",
    "if CHECKPOINT_PATH is None:\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.grad is None:\n",
    "            print(name)\n",
    "model.metrics.update(pred,batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=128)\n",
    "# pts = pred['mid_output']['sampled_feats'][0].reshape(-1,2,128).sigmoid()\n",
    "# row, column = 1, 2\n",
    "# fig, ax = plt.subplots(row, column, figsize=(10, 4))\n",
    "# for i in range(2):\n",
    "#     feat = pts[:,i]#.reshape(-1, 128)\n",
    "#     feat_ = pca.fit_transform(feat).reshape(200,200,128)\n",
    "#     ax[i].imshow(feat_[:,:,:50].sum(-1))\n",
    "    # ax[i//column, i%column].imshow(feat_[:,:,:1])\n",
    "# feat = pred['height']['sampled_feat'][0,128:256].permute(1,2,0).reshape(-1, 128)\n",
    "# feat_ = pca.fit_transform(feat).reshape(200,200,128)\n",
    "# plt.imshow(feat_[:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 0\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8))\n",
    "y = 20\n",
    "x = 97\n",
    "vehicle_idx = [[4,5,6,7,8,10,11]]\n",
    "vehicles = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in vehicle_idx]\n",
    "vehicles = torch.cat(vehicles, 1)\n",
    "ax1.imshow(vehicles[batch_index,0].detach().cpu().numpy())\n",
    "ax1.scatter([x],[y], s=2, c='r')\n",
    "ax1.set_title('gt')\n",
    "\n",
    "ax2.imshow(((pred['VEHICLE'][batch_index,0].sigmoid().detach().cpu())).numpy())\n",
    "ax2.scatter([x],[y], s=2, c='r')\n",
    "ax2.set_title('Prediction')\n",
    "# plt.title('2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean height supervised\n",
    "x = [[[0.2583, 0.5916]],\n",
    "\n",
    "        [[0.2611, 0.5548]],\n",
    "\n",
    "        [[0.2590, 0.5263]],\n",
    "\n",
    "        [[0.2577, 0.4973]],\n",
    "\n",
    "        [[0.2594, 0.4648]],\n",
    "\n",
    "        [[0.2635, 0.4029]],\n",
    "\n",
    "        [[0.2552, 0.3652]],\n",
    "\n",
    "        [[0.2559, 0.3101]]]\n",
    "\n",
    "y = [[[0.2996, 0.5774]],\n",
    "\n",
    "        [[0.3006, 0.5427]],\n",
    "\n",
    "        [[0.2995, 0.5147]],\n",
    "\n",
    "        [[0.2988, 0.4870]],\n",
    "\n",
    "        [[0.2990, 0.4578]],\n",
    "\n",
    "        [[0.3013, 0.3992]],\n",
    "\n",
    "        [[0.2969, 0.3625]],\n",
    "\n",
    "        [[0.2972, 0.3111]]]\n",
    "\n",
    "z = [[[0.3370, 0.5645]],\n",
    "\n",
    "        [[0.3387, 0.5318]],\n",
    "\n",
    "        [[0.3373, 0.5054]],\n",
    "\n",
    "        [[0.3364, 0.4787]],\n",
    "\n",
    "        [[0.3373, 0.4501]],\n",
    "\n",
    "        [[0.3396, 0.3953]],\n",
    "\n",
    "        [[0.3343, 0.3607]],\n",
    "\n",
    "        [[0.3348, 0.3138]]]\n",
    "\n",
    "x = np.array(x)[:,0]\n",
    "x[:, 0] *= 480\n",
    "x[:, 1] *= 224\n",
    "\n",
    "y = np.array(y)[:,0]\n",
    "y[:, 0] *= 480\n",
    "y[:, 1] *= 224\n",
    "\n",
    "z = np.array(z)[:,0]\n",
    "z[:, 0] *= 480\n",
    "z[:, 1] *= 224\n",
    "\n",
    "plt.imshow(batch['image'][0,2].cpu().permute(1,2,0))\n",
    "plt.scatter(x[:,0],x[:,1],s=1, c='b')\n",
    "plt.scatter(y[:,0],y[:,1],s=1, c='g')\n",
    "plt.scatter(z[:,0],z[:,1],s=1, c='r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vis_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "# Load the nuScenes dataset (mini-split, in this case).\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/hcis-s20/SRL/nuscenes/trainval/', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "nusc.render_sample(batch['token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.label_indices = [4, 5, 6, 7,8,9,10,11]\n",
    "# from cross_view_transformer.visualizations.common import get_colors\n",
    "# SEMANTICS = [viz.SEMANTICS[i] for i in viz.label_indices]\n",
    "# viz.colors = get_colors(SEMANTICS)\n",
    "for batch in loader:\n",
    "    break\n",
    "plt.imshow(viz.visualize_bev(batch['bev'][0], batch['view'][0].numpy()))\n",
    "# plt.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(viz(batch)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((4, 40000, 1, 8, 128))\n",
    "a = a.reshape(4 *40000,8, 128)\n",
    "attention = nn.MultiheadAttention(128, 4, batch_first=True)\n",
    "attention(a, a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.__getitem__(4004)\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        batch[k] = v[None]\n",
    "# with torch.no_grad():\n",
    "#     pred = network(batch)\n",
    "pred = None\n",
    "vis_result = viz(batch, pred)\n",
    "plt.imshow(vis_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred['VEHICLE'][0,0].sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand((5))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a > 0.6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlane\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroad_segment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroad_divider\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlane_divider\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruck\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrailer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstruction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpedestrian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotorcycle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicycle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memergency\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvt_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

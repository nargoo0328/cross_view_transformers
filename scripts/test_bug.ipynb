{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fb163730610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from common import get_cfg, prepare_val\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATASET_DIR = '/media/hcis-s20/SRL/nuscenes/trainval/'\n",
    "vehicle_idx = [4, 5, 6, 7, 8, 10, 11,12]\n",
    "DYNAMIC = [\n",
    "    'car', 'truck', 'bus',\n",
    "    'trailer', 'construction_vehicle',\n",
    "    'pedestrian',\n",
    "    'motorcycle', 'bicycle',\n",
    "    # 'emergency',\n",
    "]\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hcis-s20/SRL/cross_view_ae/cross_view_transformers/scripts/common.py:50: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path='../config')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Dataset length: 6019\n"
     ]
    }
   ],
   "source": [
    "version = 'cvt_labels_nuscenes_v3'\n",
    "cfg1 = get_cfg(DATASET_DIR, version, 'SparseBEVSeg_Det_3') # cvt_nuscenes_multiclass Sparse\n",
    "device = torch.device('cuda:0') # cuda:5\n",
    "model_version = '2024_0827_180109'\n",
    "CHECKPOINT_PATH = None\n",
    "# CHECKPOINT_PATH = '../logs/cross_view_transformers_test/' + model_version +'/checkpoints/last.ckpt'\n",
    "model, network, loader, viz, dataset = prepare_val(cfg1, device, CHECKPOINT_PATH, mode='val', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    }
   ],
   "source": [
    "network.to(device)\n",
    "model.to(device)\n",
    "model.metrics.reset()\n",
    "with_grad = True\n",
    "\n",
    "if with_grad:\n",
    "    network.train()\n",
    "    # with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        if i != 0:\n",
    "            continue\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(device)\n",
    "            elif isinstance(v, list):\n",
    "                if isinstance(v[0], torch.Tensor):\n",
    "                    batch[k] = [i.to(device) for i in v]\n",
    "            else:\n",
    "                batch[k] = v\n",
    "        pred = network(batch)\n",
    "        loss = model.loss_func(pred,batch)\n",
    "        loss[0].backward()\n",
    "        vis_result = viz(batch,pred)\n",
    "        break\n",
    "else:\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(loader):\n",
    "            print(i,end='\\r')\n",
    "            for k, v in batch.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    batch[k] = v.to(device)\n",
    "                elif isinstance(v, list):\n",
    "                    if isinstance(v[0], torch.Tensor):\n",
    "                        batch[k] = [i.to(device) for i in v]\n",
    "                else:\n",
    "                    batch[k] = v\n",
    "            pred = network(batch)\n",
    "            model.metrics.update(pred,batch)\n",
    "            # pred['mid_output']['sampled_feats'].retain_grad()\n",
    "            # loss = model.loss_func(pred,batch)\n",
    "            # loss[0].backward()\n",
    "            # vis_result = viz(batch,pred)\n",
    "    # if i ==5:\n",
    "            # break   \n",
    "        \n",
    "# if CHECKPOINT_PATH is None:\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if param.requires_grad and param.grad is None:\n",
    "#             print(name)\n",
    "# model.metrics.update(pred,batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IoU_VEHICLE': tensor(0.3902, device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['mid_output']['inter_output'][0]\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=128)\n",
    "feat = pred['mid_output']['inter_output'][1][0].reshape(128, 200, 200).permute(1,2,0).view(-1, 128).sigmoid().detach().numpy()\n",
    "# feat = pca.fit_transform(feat).reshape(200,200,128)\n",
    "feat = feat.reshape(200,200,128)\n",
    "row, column = 1, 4\n",
    "fig, ax = plt.subplots(row, column, figsize=(10, 4))\n",
    "for i in range(column):\n",
    "    ax[i].imshow(feat[:,:,i+12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 0\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8))\n",
    "y = 146\n",
    "x = 77\n",
    "vehicle_idx = [[4,5,6,7,8,10,11]]\n",
    "vehicles = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in vehicle_idx]\n",
    "vehicles = torch.cat(vehicles, 1)\n",
    "ax1.imshow(vehicles[batch_index,0].detach().cpu().numpy())\n",
    "ax1.scatter([x],[y], s=2, c='r')\n",
    "ax1.set_title('gt')\n",
    "\n",
    "ax2.imshow(((pred['VEHICLE'][batch_index,0].sigmoid().detach().cpu())).numpy())\n",
    "ax2.scatter([x],[y], s=2, c='r')\n",
    "ax2.set_title('Prediction')\n",
    "# plt.title('2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean height supervised\n",
    "x = [[[0.7693, 0.5553]],\n",
    "\n",
    "        [[0.7684, 0.5310]],\n",
    "\n",
    "        [[0.7685, 0.5168]],\n",
    "\n",
    "        [[0.7683, 0.4997]],\n",
    "\n",
    "        [[0.7683, 0.4792]],\n",
    "\n",
    "        [[0.7686, 0.4479]],\n",
    "\n",
    "        [[0.7634, 0.4275]],\n",
    "\n",
    "        [[0.7679, 0.4024]]]\n",
    "\n",
    "y = [[[0.7473, 0.5565]],\n",
    "\n",
    "        [[0.7465, 0.5323]],\n",
    "\n",
    "        [[0.7466, 0.5182]],\n",
    "\n",
    "        [[0.7464, 0.5010]],\n",
    "\n",
    "        [[0.7463, 0.4806]],\n",
    "\n",
    "        [[0.7467, 0.4494]],\n",
    "\n",
    "        [[0.7417, 0.4290]],\n",
    "\n",
    "        [[0.7460, 0.4040]]]\n",
    "\n",
    "z = [[[0.7254, 0.5597]],\n",
    "\n",
    "        [[0.7246, 0.5356]],\n",
    "\n",
    "        [[0.7247, 0.5219]],\n",
    "\n",
    "        [[0.7244, 0.5047]],\n",
    "\n",
    "        [[0.7244, 0.4842]],\n",
    "\n",
    "        [[0.7248, 0.4530]],\n",
    "\n",
    "        [[0.7195, 0.4330]],\n",
    "\n",
    "        [[0.7241, 0.4074]]]\n",
    "\n",
    "x = np.array(x)[:,0]\n",
    "x[:, 0] *= 480\n",
    "x[:, 1] *= 224\n",
    "\n",
    "y = np.array(y)[:,0]\n",
    "y[:, 0] *= 480\n",
    "y[:, 1] *= 224\n",
    "\n",
    "z = np.array(z)[:,0]\n",
    "z[:, 0] *= 480\n",
    "z[:, 1] *= 224\n",
    "\n",
    "plt.imshow(batch['image'][0,4].cpu().permute(1,2,0))\n",
    "plt.scatter(x[:,0],x[:,1],s=1, c='b')\n",
    "plt.scatter(y[:,0],y[:,1],s=1, c='g')\n",
    "plt.scatter(z[:,0],z[:,1],s=1, c='r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vis_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "# Load the nuScenes dataset (mini-split, in this case).\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/hcis-s20/SRL/nuscenes/trainval/', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "nusc.render_sample(batch['token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.label_indices = [4, 5, 6, 7,8,9,10,11]\n",
    "# from cross_view_transformer.visualizations.common import get_colors\n",
    "# SEMANTICS = [viz.SEMANTICS[i] for i in viz.label_indices]\n",
    "# viz.colors = get_colors(SEMANTICS)\n",
    "for batch in loader:\n",
    "    break\n",
    "plt.imshow(viz.visualize_bev(batch['bev'][0], batch['view'][0].numpy()))\n",
    "# plt.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(viz(batch)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((4, 40000, 1, 8, 128))\n",
    "a = a.reshape(4 *40000,8, 128)\n",
    "attention = nn.MultiheadAttention(128, 4, batch_first=True)\n",
    "attention(a, a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.__getitem__(4004)\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        batch[k] = v[None]\n",
    "# with torch.no_grad():\n",
    "#     pred = network(batch)\n",
    "pred = None\n",
    "vis_result = viz(batch, pred)\n",
    "plt.imshow(vis_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred['VEHICLE'][0,0].sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand((5))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a > 0.6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(loader):\n",
    "    break\n",
    "img = batch['bev']\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8))\n",
    "vehicle_idx = [[4,5,6,7,8,10,11]]\n",
    "vehicles = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in vehicle_idx]\n",
    "vehicles = torch.cat(vehicles, 1)\n",
    "ax1.imshow(vehicles[0,0])\n",
    "vehicles = F.interpolate(vehicles, size=[25,25], mode='bilinear')\n",
    "ax2.imshow(vehicles[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = F.interpolate(vehicles, size=[200,200], mode='bilinear')\n",
    "plt.imshow(vehicles[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "camera = nn.Embedding(6, 128)\n",
    "camera(torch.tensor([0,1,2])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvt_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

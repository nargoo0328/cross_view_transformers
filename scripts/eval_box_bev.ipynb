{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import Box\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/hcis-s20/SRL/nuscenes/trainval/', verbose=True)\n",
    "# bevformer_results = mmcv.load(\"/media/hcis-s20/SRL/det3d/BEVFormer/test/bevformer_base/Wed_Mar__6_21_42_43_2024/pts_bbox/results_nusc.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/tmp/tmp4ywinw5c/results/pred_instances_3d/results_nusc.json\"\n",
    "file_name = \"/media/hcis-s20/SRL/det3d/SparseBEV/submission/pts_bbox/results_nusc.json\" \n",
    "bevformer_results = mmcv.load(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation_matrix(R, t, inv=False):\n",
    "    pose = np.eye(4, dtype=np.float32)\n",
    "    pose[:3, :3] = R if not inv else R.T\n",
    "    pose[:3, -1] = t if not inv else R.T @ -t\n",
    "\n",
    "    return pose\n",
    "\n",
    "\n",
    "def get_pose(rotation, translation, inv=False, flat=False):\n",
    "    if flat:\n",
    "        yaw = Quaternion(rotation).yaw_pitch_roll[0]\n",
    "        R = Quaternion(scalar=np.cos(yaw / 2), vector=[0, 0, np.sin(yaw / 2)]).rotation_matrix\n",
    "    else:\n",
    "        R = Quaternion(rotation).rotation_matrix\n",
    "\n",
    "    t = np.array(translation, dtype=np.float32)\n",
    "\n",
    "    return get_transformation_matrix(R, t, inv=inv)\n",
    "\n",
    "def get_bev_from_box(\n",
    "        nusc,\n",
    "        batch,\n",
    "        pred, \n",
    "        threshold,\n",
    "        class_name = [  ['car', 'truck', 'bus','trailer', 'construction','motorcycle', 'bicycle',],\n",
    "                        ['pedestrian']\n",
    "                     ]\n",
    "    ):\n",
    "    def get_class_index(name):\n",
    "        for i in range(len(class_name)):\n",
    "            if name in class_name[i]:\n",
    "                return i\n",
    "        return -1\n",
    "    token = batch['token'][0]\n",
    "\n",
    "    sample = nusc.get('sample', token)\n",
    "    sample_data_token = sample['data']['LIDAR_TOP']\n",
    "    sd_record = nusc.get('sample_data', sample_data_token)\n",
    "    pose_record = nusc.get('ego_pose', sd_record['ego_pose_token'])\n",
    "\n",
    "    boxes = [Box(record['translation'], record['size'], Quaternion(record['rotation']),\n",
    "                         name=record['detection_name'], token='predicted') for record in\n",
    "                     pred['results'][token] if record['detection_score'] > threshold]\n",
    "    pose_inv = get_pose(pose_record['rotation'],pose_record['translation'], inv=True)\n",
    "    # pose_inv = batch['pose_inverse'][0].cpu().numpy()\n",
    "    V = batch['view'][0].cpu().numpy()\n",
    "    S = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ]) \n",
    "    render = np.zeros((len(class_name), 200, 200), dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        index = get_class_index(box.name)\n",
    "        if index == -1:\n",
    "            continue\n",
    "\n",
    "        p = box.bottom_corners()\n",
    "        p = np.pad(p, ((0, 1), (0, 0)), constant_values=1.0)                        \n",
    "        p = V @ S @ pose_inv @ p        \n",
    "        # p = p[:2, :4]\n",
    "        # p = V @ S  @ p        \n",
    "        p = p[:2]\n",
    "        cv2.fillPoly(render[index], [p.round().astype(np.int32).T], 1, cv2.LINE_8)\n",
    "    \n",
    "    return render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from common import get_cfg, prepare_val\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATASET_DIR = '/media/hcis-s20/SRL/nuscenes/trainval/'\n",
    "vehicle_idx = [4, 5, 6, 7, 8, 10, 11,12]\n",
    "DYNAMIC = [\n",
    "    'car', 'truck', 'bus',\n",
    "    'trailer', 'construction_vehicle',\n",
    "    'pedestrian',\n",
    "    'motorcycle', 'bicycle',\n",
    "    # 'emergency',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcis-s20/miniconda3/envs/cvt_2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Dataset length: 6019\n"
     ]
    }
   ],
   "source": [
    "version = 'cvt_labels_nuscenes_v3'\n",
    "cfg1 = get_cfg(DATASET_DIR, version, 'BEVSD') # cvt_nuscenes_multiclass nuscenes_detr3d\n",
    "device = torch.device('cpu') # cuda:5\n",
    "# best resnet: 0830_232653, origin cvt: 0824_024032\n",
    "CHECKPOINT_PATH = None # '../logs/cross_view_transformers_test/0415_180119/checkpoints/last.ckpt'\n",
    "model, network, loader, viz, _ = prepare_val(cfg1,device,CHECKPOINT_PATH,mode='val',batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 28129, max_v: 3587, max_p: 219\r"
     ]
    }
   ],
   "source": [
    "max_vehicles = 0.0\n",
    "max_peds = 0.0\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(f\"Index: {i}, max_v: {max_vehicles}, max_p: {max_peds}\", end='\\r')\n",
    "        vehicle_idx = [[4,5,6,7,8,10,11]]\n",
    "        vehicles = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in vehicle_idx]\n",
    "        vehicles = torch.cat(vehicles, 1)\n",
    "        vehicles = vehicles[0,0].bool() & batch['visibility'][0]\n",
    "\n",
    "        ped_idx = [[9]]\n",
    "        peds = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in ped_idx]\n",
    "        peds = torch.cat(peds, 1)\n",
    "        peds = peds[0,0].bool() & batch['visibility_ped'][0]\n",
    "        # if with_visibility:\n",
    "        #     if 9 in class_index[0]:\n",
    "        #         visibility = batch['visibility_ped'][0]\n",
    "        #     else:\n",
    "        #         visibility = batch['visibility'][0]\n",
    "\n",
    "        max_vehicles = max(max_vehicles, vehicles.sum())\n",
    "        max_peds = max(max_peds, peds.sum())\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.to(device)\n",
    "network.eval()\n",
    "model.to(device)\n",
    "model.metrics.reset()\n",
    "preds = []\n",
    "scores_vehicles = []\n",
    "scores_peds = []\n",
    "threshold = 0.8\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(device)\n",
    "            elif isinstance(v, list):\n",
    "                if isinstance(v[0], torch.Tensor):\n",
    "                    batch[k] = [i.to(device) for i in v]\n",
    "            else:\n",
    "                batch[k] = v\n",
    "        # break\n",
    "        # \n",
    "        bev_render = np.zeros((1,1,200,200),np.float32)\n",
    "        for j in range(8):\n",
    "            if j+4 == 9:\n",
    "                continue\n",
    "            label = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in [[j+4]]]\n",
    "            label = torch.cat(label, 1)[0,0]\n",
    "            pts = map2points(label.cpu().numpy())\n",
    "            if len(pts) == 0:\n",
    "                continue\n",
    "            clusters = apply_dbscan(pts,1.0,3)\n",
    "            if len(clusters) == 0:\n",
    "                continue\n",
    "            for k in range(clusters.max()+1):\n",
    "                # if i<clusters.max():\n",
    "                #     continue\n",
    "                tmp_index = np.where(clusters==k)[0]\n",
    "                t_c = tmp_calculate()\n",
    "                x1, x2, y1, y2 = t_c.compute(pts[tmp_index])\n",
    "                score = label[y1:y2,x1:x2].sum()/((x2-x1)*(y2-y1))\n",
    "                scores_vehicles.append(score)\n",
    "                if score < threshold:\n",
    "                    continue\n",
    "                # bev_render[0,0,y1:y2,x1:x2] = 1.0\n",
    "                cv2.rectangle(bev_render[0,0], (x1, y1), (x2, y2), 1, -1)\n",
    "        \n",
    "        ped_render = np.zeros((1,1,200,200),np.float32)\n",
    "        label = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in [[9]]]\n",
    "        label = torch.cat(label, 1)[0,0]\n",
    "        pts = map2points(label.cpu().numpy())\n",
    "        if len(pts) == 0:\n",
    "            continue\n",
    "        clusters = apply_dbscan(pts,1.0,3)\n",
    "        if len(clusters) == 0:\n",
    "            continue\n",
    "        for k in range(clusters.max()+1):\n",
    "            # if i<clusters.max():\n",
    "            #     continue\n",
    "            tmp_index = np.where(clusters==k)[0]\n",
    "            t_c = tmp_calculate()\n",
    "            x1, x2, y1, y2 = t_c.compute(pts[tmp_index])\n",
    "            score = label[y1:y2,x1:x2].sum()/((x2-x1)*(y2-y1))\n",
    "            scores_peds.append(score)\n",
    "            if score < threshold:\n",
    "                continue\n",
    "            # ped_render[0,0,y1:y2,x1:x2] = 1.0\n",
    "            cv2.rectangle(ped_render[0,0], (x1, y1), (x2, y2), 1, -1)\n",
    "            \n",
    "        # pred = {}\n",
    "        # pred['bev'] = torch.from_numpy(bev_render).to(device)\n",
    "        # pred['ped'] = torch.from_numpy(ped_render).to(device)\n",
    "\n",
    "        # model.metrics.update(pred,batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.metrics.compute()\n",
    "for s in ['iou_ped','iou_vehicle']:\n",
    "    print(result[s]['@0.60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# df = px.data.tips()\n",
    "scores = torch.stack(scores_vehicles).cpu().numpy()\n",
    "fig = px.histogram(scores, range_x=[0.0, 1.0], title='Train set Vehicles statistic')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "scores = torch.stack(scores_vehicles).cpu().numpy()\n",
    "fig = go.Figure(data=[go.Histogram(x=scores, cumulative_enabled=True, histnorm='percent')])\n",
    "\n",
    "# Set the title and labels\n",
    "fig.update_layout(\n",
    "    title_text='Val set Vehicles statistic', \n",
    "    xaxis_title_text='Score', \n",
    "    yaxis_title_text='Percentage', \n",
    "    bargap=0.2, \n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "scores = torch.stack(scores_peds).cpu().numpy()\n",
    "fig = go.Figure(data=[go.Histogram(x=scores, cumulative_enabled=True, histnorm='percent')])\n",
    "\n",
    "# Set the title and labels\n",
    "fig.update_layout(\n",
    "    title_text='Val set Peds statistic', \n",
    "    xaxis_title_text='Score', \n",
    "    yaxis_title_text='Percentage', \n",
    "    bargap=0.2, \n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 200, 200, 8]) torch.Size([3, 200, 200, 8])\n",
      "tensor([[-50.0000, -50.0000,   0.0000],\n",
      "        [-50.0000, -50.0000,   0.5714],\n",
      "        [-50.0000, -50.0000,   1.1429],\n",
      "        [-50.0000, -50.0000,   1.7143],\n",
      "        [-50.0000, -50.0000,   2.2857],\n",
      "        [-50.0000, -50.0000,   2.8571],\n",
      "        [-50.0000, -50.0000,   3.4286],\n",
      "        [-50.0000, -50.0000,   4.0000]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 2],\n",
      "        [0, 0, 3],\n",
      "        [0, 0, 4],\n",
      "        [0, 0, 5],\n",
      "        [0, 0, 6],\n",
      "        [0, 0, 7]], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(a[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(b[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     34\u001b[0m x1, y1, z1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmeshgrid(\n\u001b[0;32m---> 35\u001b[0m             torch\u001b[38;5;241m.\u001b[39marange(\u001b[43mX\u001b[49m), torch\u001b[38;5;241m.\u001b[39marange(Y), torch\u001b[38;5;241m.\u001b[39marange(Z), indexing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mij\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def _set_cache_dense_coords():\n",
    "    \"\"\"Get, and / or, set dense coordinates used during training and validation.\"\"\"\n",
    "    spatial_range = 200, 200, 8\n",
    "    spatial_bounds = [-50.0, -50.0, 0.0, 50.0, 50.0, 4.0]\n",
    "    # Alias\n",
    "    X, Y, Z = spatial_range\n",
    "    XMIN, YMIN, ZMIN, XMAX, YMAX, ZMAX = spatial_bounds\n",
    "\n",
    "    # Coordinates\n",
    "    # (3, rX, rY, Z), r for reverse order.\n",
    "    dense_vox_coords = torch.stack(\n",
    "        torch.meshgrid(\n",
    "            torch.linspace(XMIN, XMAX, X, dtype=torch.float64),\n",
    "            torch.linspace(YMIN, YMAX, Y, dtype=torch.float64),\n",
    "            torch.linspace(ZMIN, ZMAX, Z, dtype=torch.float64),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "    ).flip(1, 2)\n",
    "    dense_vox_coords = dense_vox_coords.float()\n",
    "\n",
    "    # Indices\n",
    "    dense_vox_idx = torch.stack(\n",
    "        torch.meshgrid(\n",
    "            torch.arange(X), torch.arange(Y), torch.arange(Z), indexing=\"ij\"\n",
    "        )\n",
    "    ).flip(1, 2).int()\n",
    "    return dense_vox_coords, dense_vox_idx\n",
    "a, b = _set_cache_dense_coords()\n",
    "print(a.shape,b.shape)\n",
    "print(a[:,-1,-1,:].transpose(0,1))\n",
    "print(b[:,-1,-1,:].transpose(0,1))\n",
    "x1, y1, z1 = torch.meshgrid(\n",
    "            torch.arange(X), torch.arange(Y), torch.arange(Z), indexing=\"ij\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in [0.2]:# [0.2,0.3,0.4,0.5,0.6,0.7]:\n",
    "    print(th)\n",
    "    model.metrics.reset()\n",
    "    for k,m in model.metrics.items():\n",
    "        m.thresholds = m.thresholds.to(device)\n",
    "        m.tp = m.tp.to(device)\n",
    "        m.fp = m.fp.to(device)\n",
    "        m.fn = m.fn.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(loader):\n",
    "            print(i,end='\\r')\n",
    "            if i == 2:\n",
    "                break\n",
    "            continue\n",
    "            render = get_bev_from_box(nusc,batch,bevformer_results,th)\n",
    "            render = np.float32(render)\n",
    "            if i == 2:\n",
    "                break\n",
    "            pred = {'bev':torch.from_numpy(render[0])[None,None].to(device),'ped':torch.from_numpy(render[1])[None,None].to(device)}\n",
    "            batch['bev'] = batch['bev'].to(device)\n",
    "            batch['visibility'] = batch['visibility'].to(device)\n",
    "            batch['visibility_ped'] = batch['visibility_ped'].to(device)\n",
    "            model.metrics.update(pred,batch)\n",
    "\n",
    "    print()\n",
    "    for k,m in model.metrics.items():\n",
    "        print(k,':\\n\\t',m.compute(),'\\n\\t','='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.to(device)\n",
    "network.eval()\n",
    "model.to(device)\n",
    "max_n = 0\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        # for k, v in batch.items():\n",
    "        #     if isinstance(v, torch.Tensor):\n",
    "        #         batch[k] = v.to(device)\n",
    "        #     elif isinstance(v, list):\n",
    "        #         if isinstance(v[0], torch.Tensor):\n",
    "        #             batch[k] = [i.to(device) for i in v]\n",
    "        #     else:\n",
    "        #         batch[k] = v\n",
    "        max_n = max(batch['labels'].shape[1],max_n)\n",
    "        # pred = network(batch)\n",
    "        # scores, labels = pred['pred_logits'].detach().softmax(-1)[:, :, :-1].max(-1)\n",
    "        # if (labels == 2).cpu().numpy().any():\n",
    "        #     print(labels)\n",
    "        #     break\n",
    "# render = np.zeros((200,200),dtype=np.uint8)\n",
    "# for (x1,y1,x2,y2), label in zip(batch['boxes'][0],batch['labels'][0]):\n",
    "#     if label >= 1:\n",
    "#         continue\n",
    "#     x1 = (x1 * 100) -50\n",
    "#     x2 = (x2 * 100) -50\n",
    "#     y1 = (y1 * 100) -50\n",
    "#     y2 = (y2 * 100) -50\n",
    "#     pts = np.array([[x1,y1,1],[x2,y2,1]]).transpose()\n",
    "#     pts = batch['view'][0].cpu().numpy() @ pts\n",
    "#     pts = pts.astype(np.uint8)\n",
    "#     x1,y1 = pts[:2,0] \n",
    "#     x2,y2 = pts[:2,1]\n",
    "#     cv2.rectangle(render, (x1, y1), (x2, y2), 1, -1)\n",
    "# plt.imshow(render)\n",
    "print(max_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(batch['boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_view_transformer.util.box_ops import box_cxcywh_to_xyxy, generalized_box_iou\n",
    "labels = batch['labels']\n",
    "boxes = batch['boxes']\n",
    "tgt_ids = torch.cat([v for v in labels])\n",
    "tgt_bbox = torch.cat([v for v in boxes])\n",
    "out_bbox = pred[\"pred_boxes\"].flatten(0, 1).cpu()\n",
    "out_prob = pred[\"pred_logits\"].flatten(0, 1).softmax(-1).cpu()\n",
    "cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))\n",
    "cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
    "cost_class = -out_prob[:, tgt_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((2),dtype=torch.long)\n",
    "test = out_prob[:5]\n",
    "cost_class = -test[:, a]\n",
    "print(test.shape)\n",
    "print(cost_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        l.append(batch)\n",
    "        if i == 30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch['bev'][0,4].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        vehicle_boxes = []\n",
    "        view_inv = batch['view'][0].inverse().cpu().numpy()\n",
    "        for j in range(len(DYNAMIC)):\n",
    "            box_list = get_bev_from_box(batch,[[j+4]],return_bb=True, with_visibility=True, view=view_inv)\n",
    "            \n",
    "            vehicle_boxes += box_list\n",
    "        \n",
    "        vehicle_boxes = np.array(vehicle_boxes)\n",
    "        vehicle_boxes = np.pad(vehicle_boxes,[(0,0),(0,1)], mode='constant', constant_values=0)\n",
    "        ped_boxes = get_bev_from_box(batch,[[9]],return_bb=True, with_visibility=True)\n",
    "        ped_boxes = np.array(ped_boxes)\n",
    "        ped_boxes = np.pad(ped_boxes,[(0,0),(0,1)], mode='constant', constant_values=1)\n",
    "        result = np.concatenate((vehicle_boxes,ped_boxes),0)\n",
    "        print(result)\n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_dbscan(data, eps, min_samples):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "    labels = clustering.labels_\n",
    "    return labels\n",
    "\n",
    "def map2points(data):\n",
    "    ys, xs = np.where(data == 1)\n",
    "    return np.array((xs, ys)).transpose()\n",
    "\n",
    "def generate_colors(number):\n",
    "    return [(randrange(255), randrange(255), randrange(255)) for _ in range(number)]\n",
    "\n",
    "def get_min_max(pts_list, h=200, w=200):\n",
    "    min_x, max_x, min_y, max_y = h, -1, w, -1\n",
    "    for (x,y) in pts_list:\n",
    "        if x < min_x:\n",
    "            min_x = x\n",
    "        if y < min_y:\n",
    "            min_y = y\n",
    "        if x > max_x:\n",
    "            max_x = x\n",
    "        if y > max_y:\n",
    "            max_y = y\n",
    "    return (min_x, min_y), (max_x, max_y)\n",
    "\n",
    "def get_bev_from_box(batch, class_index=[[4, 5, 6, 7, 8, 10, 11,12]], return_clusters=False, return_bb=False, with_visibility=False, view=None):\n",
    "    label = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in class_index]\n",
    "    label = torch.cat(label, 1)\n",
    "    if with_visibility:\n",
    "        if 9 in class_index[0]:\n",
    "            visibility = batch['visibility_ped'][0]\n",
    "        else:\n",
    "            visibility = batch['visibility'][0]\n",
    "        label = label * (visibility>=2)\n",
    "    render = np.zeros((200,200),np.uint8)\n",
    "    bev_pts = map2points(label[0,0])\n",
    "\n",
    "    if len(bev_pts) == 0:\n",
    "        return [] if return_bb else render\n",
    "\n",
    "    clusters = apply_dbscan(bev_pts,1.0,3)\n",
    "    if return_clusters:\n",
    "        return clusters\n",
    "    if return_bb:\n",
    "        box_list = []\n",
    "    for j in range(clusters.max()+1):\n",
    "        tmp_index = np.where(clusters==j)[0]\n",
    "        (x1,y1),(x2,y2) = get_min_max(bev_pts[tmp_index])\n",
    "        if return_bb:\n",
    "            if view is not None:\n",
    "                pts = np.array([[x1,y1,1],[x2,y2,1]]).transpose()\n",
    "                # pts = np.array([[(x1+x2)/2,(y1+y2)/2,1]]).transpose()\n",
    "                pts = view @ pts\n",
    "                x1, y1, x2, y2 = pts[:2].transpose().reshape(-1)\n",
    "                x1 = (x1+50) / 100\n",
    "                x2 = (x2+50) / 100\n",
    "                y1 = (y1+50) / 100\n",
    "                y2 = (y2+50) / 100\n",
    "\n",
    "            box_list.append([x1,y1,x2,y2])\n",
    "        else:\n",
    "            cv2.rectangle(render, (x1, y1), (x2, y2), 1, -1)\n",
    "\n",
    "    return box_list if return_bb else render\n",
    "\n",
    "def image_(pts,h=224,w=480):\n",
    "    n = pts.shape[-1]\n",
    "    if n == 0:\n",
    "        return pts\n",
    "    mask = torch.ones((n), dtype=bool)\n",
    "    mask = mask & (pts[0, :] < w-1)\n",
    "    mask = mask & (pts[0, :] > 1) \n",
    "    mask = mask & (pts[1, :] > 1)\n",
    "    mask = mask & (pts[1, :] < h-1)\n",
    "    return pts[:,mask]\n",
    "\n",
    "def view_points(points, view) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This is a helper class that maps 3d points to a 2d plane. It can be used to implement both perspective and\n",
    "    orthographic projections. It first applies the dot product between the points and the view. By convention,\n",
    "    the view should be such that the data is projected onto the first 2 axis. It then optionally applies a\n",
    "    normalization along the third dimension.\n",
    "\n",
    "    For a perspective projection the view should be a 3x3 camera matrix, and normalize=True\n",
    "    For an orthographic projection with translation the view is a 3x4 matrix and normalize=False\n",
    "    For an orthographic projection without translation the view is a 3x3 matrix (optionally 3x4 with last columns\n",
    "     all zeros) and normalize=False\n",
    "\n",
    "    :param points: <np.float32: 3, n> Matrix of points, where each point (x, y, z) is along each column.\n",
    "    :param view: <np.float32: n, n>. Defines an arbitrary projection (n <= 4).\n",
    "        The projection should be such that the corners are projected onto the first 2 axis.\n",
    "    :param normalize: Whether to normalize the remaining coordinate (along the third axis).\n",
    "    :return: <np.float32: 3, n>. Mapped point. If normalize=False, the third coordinate is the height.\n",
    "    \"\"\"\n",
    "\n",
    "    viewpad = np.eye(4)\n",
    "    viewpad[:view.shape[0], :view.shape[1]] = view\n",
    "\n",
    "    nbr_points = points.shape[1]\n",
    "\n",
    "    # Do operation in homogenous coordinates.\n",
    "    points = np.concatenate((points, np.ones((1, nbr_points))))\n",
    "    points = np.dot(viewpad, points)\n",
    "    points = points[:3, :]\n",
    "\n",
    "    points = points / points[2:3, :].repeat(3, 0).reshape(3, nbr_points)\n",
    "\n",
    "    return points\n",
    "\n",
    "def project_points(batch,cam_index,points,filter=False):\n",
    "    intrinsics = batch['intrinsics'][0,cam_index].cpu().numpy()\n",
    "    extrinsics = batch['extrinsics'][0,cam_index].cpu().numpy()\n",
    "    points = extrinsics @ points\n",
    "    depths = points[2]\n",
    "    points = view_points(points[:3], intrinsics)\n",
    "    points = points[:,depths > 1.0]\n",
    "    print(points.shape)\n",
    "    if not filter:\n",
    "        return points\n",
    "    points = image_(points)\n",
    "    return points\n",
    "\n",
    "class tmp_calculate:\n",
    "    def __init__(self, h=200, w=200):\n",
    "        self.x1s = []\n",
    "        self.x2s = []\n",
    "        self.y1s = []\n",
    "        self.y2s = []\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def compute(self, pts_list):\n",
    "        h = self.h\n",
    "        w = self.w\n",
    "        min_x, max_x, min_y, max_y = h, -1, w, -1\n",
    "        for (x,y) in pts_list:\n",
    "            if x < min_x:\n",
    "                min_x = x\n",
    "                self.x1s = []\n",
    "                self.x1s.append([x,y])\n",
    "            elif x == min_x:\n",
    "                self.x1s.append([x,y])\n",
    "            if y < min_y:\n",
    "                min_y = y\n",
    "                self.y1s = []\n",
    "                self.y1s.append([x,y])\n",
    "            elif y == min_y:\n",
    "                self.y1s.append([x,y])\n",
    "            if x > max_x:\n",
    "                max_x = x\n",
    "                self.x2s = []\n",
    "                self.x2s.append([x,y])\n",
    "            elif x == max_x:\n",
    "                self.x2s.append([x,y])\n",
    "            if y > max_y:\n",
    "                max_y = y\n",
    "                self.y2s = []\n",
    "                self.y2s.append([x,y])\n",
    "            elif y == max_y:\n",
    "                self.y2s.append([x,y])\n",
    "\n",
    "        return min_x, max_x, min_y, max_y # self.x1s, self.x2s, self.y1s, self.y2s\n",
    "\n",
    "    def get_pts(self):\n",
    "        def cal_distance(pt1, pt2):\n",
    "            return np.sqrt((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)\n",
    "        out = []\n",
    "        used = []\n",
    "        for pt_list in [self.x1s,self.y1s,self.x2s,self.y2s]:\n",
    "            max_dis, max_pt = 0.0, None\n",
    "            for pt in pt_list:\n",
    "                if len(used) != 0:\n",
    "                    for pt2 in used:\n",
    "                        dis = cal_distance(pt,pt2)\n",
    "                        if dis > max_dis:\n",
    "                            max_dis = dis\n",
    "                            max_pt = pt\n",
    "                else:\n",
    "                    max_pt = pt\n",
    "                    break\n",
    "            out.append(max_pt)\n",
    "            used.append(max_pt)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tmp_calculate:\n",
    "    def __init__(self, h=200, w=200):\n",
    "        self.x1s = []\n",
    "        self.x2s = []\n",
    "        self.y1s = []\n",
    "        self.y2s = []\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def compute(self, pts_list):\n",
    "        h = self.h\n",
    "        w = self.w\n",
    "        min_x, max_x, min_y, max_y = h, -1, w, -1\n",
    "        for (x,y) in pts_list:\n",
    "            if x < min_x:\n",
    "                min_x = x\n",
    "                self.x1s = []\n",
    "                self.x1s.append([x,y])\n",
    "            elif x == min_x:\n",
    "                self.x1s.append([x,y])\n",
    "            if y < min_y:\n",
    "                min_y = y\n",
    "                self.y1s = []\n",
    "                self.y1s.append([x,y])\n",
    "            elif y == min_y:\n",
    "                self.y1s.append([x,y])\n",
    "            if x > max_x:\n",
    "                max_x = x\n",
    "                self.x2s = []\n",
    "                self.x2s.append([x,y])\n",
    "            elif x == max_x:\n",
    "                self.x2s.append([x,y])\n",
    "            if y > max_y:\n",
    "                max_y = y\n",
    "                self.y2s = []\n",
    "                self.y2s.append([x,y])\n",
    "            elif y == max_y:\n",
    "                self.y2s.append([x,y])\n",
    "\n",
    "        return min_x, max_x, min_y, max_y # self.x1s, self.x2s, self.y1s, self.y2s\n",
    "\n",
    "    def get_pts(self):\n",
    "        def cal_distance(pt1, pt2):\n",
    "            return np.sqrt((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)\n",
    "        out = []\n",
    "        used = []\n",
    "        for pt_list in [self.x1s,self.y1s,self.x2s,self.y2s]:\n",
    "            max_dis, max_pt = 0.0, None\n",
    "            for pt in pt_list:\n",
    "                if len(used) != 0:\n",
    "                    for pt2 in used:\n",
    "                        dis = cal_distance(pt,pt2)\n",
    "                        if dis > max_dis:\n",
    "                            max_dis = dis\n",
    "                            max_pt = pt\n",
    "                else:\n",
    "                    max_pt = pt\n",
    "                    break\n",
    "            out.append(max_pt)\n",
    "            used.append(max_pt)\n",
    "            \n",
    "        return out\n",
    "render = np.zeros((200,200,3),np.uint8)\n",
    "tmp = np.zeros((200,200),np.int32)\n",
    "label = [batch['bev'][:, idx].max(1, keepdim=True).values for idx in [[4,5,6,7,8,10,11]]]\n",
    "label = torch.cat(label, 1)[0,0]\n",
    "pts = map2points(label.cpu().numpy())\n",
    "clusters = apply_dbscan(pts,1.0,3)\n",
    "scores = []\n",
    "for i in range(clusters.max()+1):\n",
    "    # if i<clusters.max():\n",
    "    #     continue\n",
    "    if i !=5:\n",
    "        continue\n",
    "    tmp_index = np.where(clusters==i)[0]\n",
    "    t_c = tmp_calculate()\n",
    "    x1, x2, y1, y2 = t_c.compute(pts[tmp_index])\n",
    "    render[y1:y2,x1:x2] = 1\n",
    "    score = label[y1:y2,x1:x2].sum()/((x2-x1)*(y2-y1))\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    cv2.rectangle(render, (x1, y1), (x2, y2), (0,255,255), -1)\n",
    "    # out = t_c.get_pts()\n",
    "    # out = np.array(out)\n",
    "    # print(out)\n",
    "    # cv2.fillPoly(render, [out], (0,255,255))\n",
    "    # plt.scatter(out[:,0],out[:,1],s=4)\n",
    "plt.title('Oriented Box')\n",
    "plt.imshow(render)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# df = px.data.tips()\n",
    "fig = px.histogram(np.array(scores), range_x=[0.0, 1.0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2,1]]\n",
    "[1,2] in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = l[1]\n",
    "img_index = 4\n",
    "img = np.ascontiguousarray((batch['image'][0,img_index].permute(1,2,0).cpu().numpy()*255).astype(np.uint8))\n",
    "\n",
    "render = get_bev_from_box(batch,class_index=[[4]],return_bb=False, with_visibility=True)\n",
    "plt.imshow(render)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def draw_3d(img, pts, linewidth=3.0):\n",
    "    pts = pts.transpose()\n",
    "    for i in range(4):\n",
    "        try:\n",
    "            cv2.line(img,\n",
    "                        (int(pts[2*i][0]), int(pts[2*i][1])),\n",
    "                        (int(pts[2*i + 1][0]), int(pts[2*i + 1][1])),\n",
    "                        linewidth)\n",
    "        except:\n",
    "            continue\n",
    "    return img\n",
    "\n",
    "def pad_points(pts, z_range=[0,2]):\n",
    "    pts_new = []\n",
    "    for pt in pts[:2].permute(1,0):\n",
    "        # for i in range((z_range[1]-z_range[0])+1):\n",
    "        #     pts_new.append(torch.Tensor([pt[0],pt[1],z_range[0]+i,1]))\n",
    "        for z in z_range:\n",
    "            pts_new.append(torch.Tensor([pt[0],pt[1],z,1]))\n",
    "    return torch.stack(pts_new).transpose(0,1)\n",
    "\n",
    "batch = l[1]\n",
    "img_index = 4\n",
    "img = np.ascontiguousarray((batch['image'][0,img_index].permute(1,2,0).cpu().numpy()*255).astype(np.uint8))\n",
    "box_list = get_bev_from_box(batch,[[4]],return_bb=True, with_visibility=True)\n",
    "pts_list = get_bev_from_box(batch, return_clusters=True)# ,[[4]]\n",
    "colors = generate_colors(len(box_list))\n",
    "view_inv = batch['view'][0].inverse()\n",
    "if True:\n",
    "    for i, (x1,y1,x2,y2) in enumerate(box_list):\n",
    "        # bev -> lidar\n",
    "        # pts = np.array([[x1,y1,1],[x2,y2,1]]).transpose()\n",
    "        pts = np.array([[x1,y1,1],[x2,y1,1],[x1,y2,1],[x2,y2,1]]).transpose()\n",
    "        # pts = np.array([[(x1+x2)/2,(y1+y2)/2,1]]).transpose()\n",
    "        pts = view_inv @ pts\n",
    "        pts = pad_points(pts).cpu().numpy()\n",
    "        pts = project_points(batch,img_index,pts)#,filter=True)\n",
    "        if pts.shape[-1] == 0:\n",
    "            continue\n",
    "        # pts = pts.astype(np.uint8)\n",
    "        top_left, bottom_right = get_min_max(pts.transpose()[:,:2],480,224)\n",
    "        # cv2.rectangle(img,(int(pts[0,5]),int(pts[1,5])),(int(pts[0,6]),int(pts[1,6])),(0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.rectangle(img,(int(top_left[0]),int(top_left[1])),(int(bottom_right[0]),int(bottom_right[1])),colors[i], 2, cv2.LINE_AA)\n",
    "        # plt.scatter(pts[0],pts[1],s=4.0)\n",
    "        # img = draw_3d(img, pts)\n",
    "else:\n",
    "    for i, pts in enumerate(pts_list):\n",
    "        # bev -> lidar\n",
    "        # print(pts)\n",
    "        # print(np.pad(pts, [(0, 0), (0, 1)], mode='constant',constant_values=1))\n",
    "        pts = np.pad(pts, [(0, 0), (0, 1)], mode='constant',constant_values=1).transpose()\n",
    "        pts = view_inv @ pts\n",
    "        pts = pad_points(pts).cpu().numpy()\n",
    "        # print(pts)\n",
    "        pts = project_points(batch,img_index,pts,filter=True)\n",
    "        if pts.shape[-1] == 0:\n",
    "            continue\n",
    "        # pts = pts.astype(np.uint8)\n",
    "        # cv2.rectangle(img,(pts[1,0],pts[1,1]),(pts[2,0],pts[2,1]),(0, 0, 255), 1, cv2.LINE_AA)\n",
    "        plt.scatter(pts[0],pts[1],s=4.0)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render = np.zeros((200,200,3),np.uint8)\n",
    "colors = generate_colors(len(box_list))\n",
    "for i,(x1,y1,x2,y2) in enumerate(box_list):\n",
    "    cv2.rectangle(render, (x1, y1), (x2, y2), colors[i], -1)\n",
    "plt.imshow(render)\n",
    "print(box_list)\n",
    "print(box_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_sample(l[1]['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = nusc.get('sample', batch['token'][0])['anns']\n",
    "for ann in anns:\n",
    "    ann = nusc.get('sample_annotation', ann)\n",
    "    if ann['token'] == 'a561a5a52e7d4069867284d2cd2a3ed3':\n",
    "        break\n",
    "    if 'pedestrian.adult' in ann['category_name'] and int(ann['visibility_token']) > 1:\n",
    "        print(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_points(points, view) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This is a helper class that maps 3d points to a 2d plane. It can be used to implement both perspective and\n",
    "    orthographic projections. It first applies the dot product between the points and the view. By convention,\n",
    "    the view should be such that the data is projected onto the first 2 axis. It then optionally applies a\n",
    "    normalization along the third dimension.\n",
    "\n",
    "    For a perspective projection the view should be a 3x3 camera matrix, and normalize=True\n",
    "    For an orthographic projection with translation the view is a 3x4 matrix and normalize=False\n",
    "    For an orthographic projection without translation the view is a 3x3 matrix (optionally 3x4 with last columns\n",
    "     all zeros) and normalize=False\n",
    "\n",
    "    :param points: <np.float32: 3, n> Matrix of points, where each point (x, y, z) is along each column.\n",
    "    :param view: <np.float32: n, n>. Defines an arbitrary projection (n <= 4).\n",
    "        The projection should be such that the corners are projected onto the first 2 axis.\n",
    "    :param normalize: Whether to normalize the remaining coordinate (along the third axis).\n",
    "    :return: <np.float32: 3, n>. Mapped point. If normalize=False, the third coordinate is the height.\n",
    "    \"\"\"\n",
    "\n",
    "    assert view.shape[0] <= 4\n",
    "    assert view.shape[1] <= 4\n",
    "    assert points.shape[0] == 3\n",
    "    viewpad = np.eye(4)\n",
    "    viewpad[:view.shape[0], :view.shape[1]] = view\n",
    "\n",
    "    nbr_points = points.shape[1]\n",
    "\n",
    "    # Do operation in homogenous coordinates.\n",
    "    points = np.concatenate((points, np.ones((1, nbr_points))))\n",
    "    points = np.dot(viewpad, points)\n",
    "    points = points[:3, :]\n",
    "\n",
    "    points = points / points[2:3, :].repeat(3, 0).reshape(3, nbr_points)\n",
    "\n",
    "    return points\n",
    "\n",
    "# GLOBAL box\n",
    "ped_box = Box(ann['translation'], ann['size'], Quaternion(ann['rotation']))\n",
    "sample = nusc.get('sample', batch['token'][0])\n",
    "cam = nusc.get('sample_data', sample['data']['CAM_BACK_LEFT'])\n",
    "\n",
    "# First step: transform from global into the ego vehicle frame for the timestamp of the image.\n",
    "poserecord = nusc.get('ego_pose', cam['ego_pose_token'])\n",
    "ped_box.translate(-np.array(poserecord['translation']))\n",
    "ped_box.rotate(Quaternion(poserecord['rotation']).inverse)\n",
    "\n",
    "# Second step: transform from ego into the camera.\n",
    "cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "ped_box.translate(-np.array(cs_record['translation']))\n",
    "ped_box.rotate(Quaternion(cs_record['rotation']).inverse)\n",
    "\n",
    "# Third step: Project to image -> 8 corners points\n",
    "corners = view_points(ped_box.bottom_corners(), cs_record['camera_intrinsic'])[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs_record['camera_intrinsic'])\n",
    "print(batch['intrinsics'][0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.render_annotation('a561a5a52e7d4069867284d2cd2a3ed3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_list = np.int32(np.array(bbox_list))\n",
    "render = np.zeros((200,200),np.uint8)\n",
    "for (y1,x1),(y2,x2) in bbox_list:\n",
    "    cv2.rectangle(render, (x1, y1), (x2, y2), 1, -1)\n",
    "plt.imshow(render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics.reset()\n",
    "for k,m in model.metrics.items():\n",
    "    m.thresholds = m.thresholds.to(device)\n",
    "    m.tp = m.tp.to(device)\n",
    "    m.fp = m.fp.to(device)\n",
    "    m.fn = m.fn.to(device)\n",
    "\n",
    "max_veihcle = 0\n",
    "max_ped = 0\n",
    "max_box = 0\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        box_vehicle = get_bev_from_box(batch,return_clusters=True)\n",
    "        box_ped = get_bev_from_box(batch,[[9]],return_clusters=True)\n",
    "        max_veihcle = max(box_vehicle.max()+1,max_veihcle)\n",
    "        max_ped = max(box_ped.max()+1,max_ped)\n",
    "        max_box = max(box_ped.max()+box_vehicle.max()+2,max_box)\n",
    "        continue\n",
    "        pred = {'bev':torch.from_numpy(box_vehicle)[None,None].to(device),'ped':torch.from_numpy(box_ped)[None,None].to(device)}\n",
    "        batch['bev'] = batch['bev'].to(device)\n",
    "        batch['visibility'] = batch['visibility'].to(device)\n",
    "        batch['visibility_ped'] = batch['visibility_ped'].to(device)\n",
    "        model.metrics.update(pred,batch)\n",
    "        # if i == 50:\n",
    "        #     break\n",
    "        \n",
    "print()\n",
    "for k,m in model.metrics.items():\n",
    "    print(k,':\\n\\t',m.compute(),'\\n\\t','='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_veihcle,max_ped,max_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "class helper:\n",
    "    def __init__(self):\n",
    "        self.n = 0.0\n",
    "        self.translation = [0.0, 0.0, 0.0]\n",
    "        self.size = [0.0, 0.0, 0.0]\n",
    "        self.rotation = [0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    def forward(self, translation, size, rotation):\n",
    "        n = self.n\n",
    "        for i in range(len(translation)):\n",
    "            v1 = self.n * self.translation[i]\n",
    "            self.translation[i] = (v1 + translation[i]) / (n+1)\n",
    "        for i in range(len(size)):\n",
    "            v1 = self.n * self.size[i]\n",
    "            self.size[i] = (v1 + size[i]) / (n+1)\n",
    "\n",
    "        for i in range(len(rotation)):\n",
    "            v1 = self.n * self.rotation[i]\n",
    "            self.rotation[i] = (v1 + rotation[i]) / (n+1)\n",
    "        \n",
    "        self.n += 1\n",
    "        # current_z_mean = self.z_mean * self.n\n",
    "        # current_z_size_mean = self.z_size_mean * self.n\n",
    "        # self.n += 1\n",
    "        # self.z_mean = (current_z_mean + z)/ self.n\n",
    "        # self.z_size_mean = (current_z_size_mean + z_size)/ self.n\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Translation mean: {self.translation}, Size mean: {self.size}, Rotation mean: {self.rotation}\"\n",
    "\n",
    "z_result = dict(\n",
    "    car = helper(),\n",
    "    truck = helper(),\n",
    "    bus = helper(),\n",
    "    trailer = helper(),\n",
    "    construction_vehicle = helper(),\n",
    "    pedestrian = helper(),\n",
    "    motorcycle = helper(),\n",
    "    bicycle = helper(),\n",
    ")\n",
    "total_ped = 0.0\n",
    "count_ped = 0.0\n",
    "for scene_record in tqdm.tqdm(nusc.scene):\n",
    "    if scene_record['name'] not in train_splits:\n",
    "        continue\n",
    "    sample_token = scene_record['first_sample_token']\n",
    "    while sample_token:\n",
    "        sample_record = nusc.get('sample', sample_token)\n",
    "        anns = sample_record['anns']\n",
    "        for ann in anns:\n",
    "            ann = nusc.get('sample_annotation', ann)\n",
    "            if int(ann['visibility_token']) < 2:\n",
    "                continue\n",
    "            for k in z_result:\n",
    "                s = k if k!= 'construction_vehicle' else 'construction'\n",
    "                if s in ann['category_name']:\n",
    "                    z_result[k].forward(ann['translation'],ann['size'],ann['rotation'])\n",
    "            if 'motorcycle' in ann['category_name']:\n",
    "                total_ped += 1\n",
    "                if ann['size'][0] <0.5 or ann['size'][1] <0.5:\n",
    "                    count_ped += 1\n",
    "        sample_token = sample_record['next']\n",
    "print(f\"{count_ped}/{total_ped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in z_result.items():\n",
    "    print(k,v)\n",
    "# car Z mean: 0.9496268797600059, Height mean: 1.7372864269667732\n",
    "# truck Z mean: 1.5562680559520412, Height mean: 2.8328014083165924\n",
    "# bus Z mean: 1.862588283304612, Height mean: 3.5100965811190528\n",
    "# trailer Z mean: 2.112663209226726, Height mean: 3.81640157906954\n",
    "# construction Z mean: 1.37493974499088, Height mean: 2.527865719489937\n",
    "# pedestrian Z mean: 1.0667289361085115, Height mean: 1.7676267494450986\n",
    "# motorcycle Z mean: 0.8392319868995608, Height mean: 1.471776610261977\n",
    "# bicycle Z mean: 0.7497402640263989, Height mean: 1.3034333333333443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/media/hcis-s20/SRL/det3d/BEVFormer/test/bevformer_base/Wed_Mar_27_10_38_55_2024/pts_bbox/results_nusc.json'\n",
    "bevformer_results = mmcv.load(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2]\n",
    "b = [-1,5,3]\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bevformer_results['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in bevformer_results['results'].items():\n",
    "    print(v[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_record in tqdm.tqdm(nusc.scene):\n",
    "    if scene_record['name'] not in val_splits:\n",
    "        continue\n",
    "    if scene_record == '30e55a3ec6184d8cb1944b39ba19d622 ':\n",
    "        print(\"HI!\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attribute = dict(\n",
    "    car = 'vehicle.moving', \n",
    "    truck = 'vehicle.parked', \n",
    "    bus = 'vehicle.moving',\n",
    "    trailer = 'vehicle.parked', \n",
    "    construction_vehicle = 'vehicle.parked',\n",
    "    pedestrian = 'pedestrian.standing',\n",
    "    motorcycle = 'cycle.with_rider', \n",
    "    bicycle = 'cycle.without_rider'\n",
    ")\n",
    "\n",
    "result = dict(\n",
    "    meta={\n",
    "        'use_lidar': False,\n",
    "        'use_camera': True,\n",
    "        'use_radar': False,\n",
    "        'use_map': False,\n",
    "        'use_external': True\n",
    "    },\n",
    "    results=dict()\n",
    ")\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(loader):\n",
    "        print(i,end='\\r')\n",
    "        tmp = []\n",
    "        token = batch['token'][0]\n",
    "        view_inv = batch['view'][0].inverse().cpu().numpy()\n",
    "        pose = batch['pose'][0].cpu().numpy()\n",
    "        for i, obj_class in enumerate(DYNAMIC):\n",
    "            attribute_name = get_attribute[obj_class]\n",
    "            z_trans, z_size = z_result[obj_class].z_mean, z_result[obj_class].z_size_mean\n",
    "            box_list = get_bev_from_box(batch,[[i+4]],return_bb=True)\n",
    "            for (x1,y1,x2,y2) in box_list:\n",
    "                _x, _y = (x2-x1) / 2.0, (y2-y1) / 2.0\n",
    "                if _x == 0.0:\n",
    "                    _x = 0.1\n",
    "                if _y == 0.0:\n",
    "                    _y = 0.1\n",
    "                center = view_inv @ np.array([(x1+x2)/2.0, (y1+y2)/2.0,1]).transpose() # bev\n",
    "                center = pose @ np.array([center[0], center[1],1,1]).transpose() # world\n",
    "                tmp.append(\n",
    "                    dict(\n",
    "                        sample_token=token,\n",
    "                        translation=[center[0],center[1],z_trans],\n",
    "                        size=[_x,_y,z_size],\n",
    "                        rotation=[0.0,0.0,0.0,0.0],\n",
    "                        velocity=[0.0,0.0],\n",
    "                        detection_name=obj_class,\n",
    "                        detection_score=0.9,\n",
    "                        attribute_name=attribute_name\n",
    "                    )\n",
    "                )\n",
    "        result['results'][token] = tmp\n",
    "\n",
    "import json\n",
    "with open('/media/hcis-s20/SRL/det3d/BEVFormer/test.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, scene_record in enumerate(nusc.scene):\n",
    "    sample_token = scene_record['first_sample_token']\n",
    "    while sample_token:\n",
    "        sample_record = nusc.get('sample', sample_token)\n",
    "        for ann in sample_record['anns']:\n",
    "            nusc.get('sample_annotation', sample_token)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3]) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.zeros((2,2,4))\n",
    "view = torch.ones((2,3,3))\n",
    "x0, y0, x1, y1 = x.unbind(-1)\n",
    "p1, p2 = torch.stack([x0,y0], dim=-1), torch.stack([x1,y1], dim=-1)\n",
    "p1, p2 = torch.nn.functional.pad(p1,(0,1), value=1), torch.nn.functional.pad(p2,(0,1), value=1)\n",
    "p1 = torch.einsum('b i j, b n j -> b n i', view, p1)\n",
    "print(p1)\n",
    "print(p1.shape,p2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Set the value of x into 1 inside each bounding box region\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     x1,y1,w,h \u001b[38;5;241m=\u001b[39m box[i,j]\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43my1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43my1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "b, h, w, n = 5, 200, 200, 100 # b: batch, h: height, w: width, n: number of bounding boxes\n",
    "x = torch.rand((b,h,w))\n",
    "box = torch.rand((b,n,4)) # bounding boxes in x1,y1,w,h\n",
    "# for each batch: b\n",
    "for i in range(b):\n",
    "    # for each box prediction\n",
    "    for j in range(n):\n",
    "        # Set the value of x into 1 inside each bounding box region\n",
    "        x1,y1,w,h = box[i,j]\n",
    "        x[i][x1:x1+w,y1:,y1+h] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 10]) torch.Size([2, 2, 4])\n",
      "tensor([[[ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False,  True,  True,  True,  True,  True,  True, False],\n",
      "         [False, False, False,  True,  True,  True,  True,  True,  True, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False]],\n",
      "\n",
      "        [[False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False,  True,  True,  True, False, False, False, False, False],\n",
      "         [False, False,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [False, False,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [False, False, False,  True,  True,  True,  True, False, False, False],\n",
      "         [False, False, False,  True,  True,  True,  True, False, False, False],\n",
      "         [False, False, False,  True,  True,  True,  True, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "h, w = 10, 10\n",
    "x = torch.zeros((2,h,w))\n",
    "box = torch.tensor([\n",
    "    [[0,0,2,2],[4,3,5,8]],\n",
    "    [[1,2,3,4],[2,3,6,6]],\n",
    "])\n",
    "print(x.shape, box.shape) # b h w, b n 4\n",
    "xx, yy = torch.meshgrid(torch.arange(h), torch.arange(w))\n",
    "xx, yy = xx.to(x.device), yy.to(x.device)\n",
    "\n",
    "# Expand dimensions for xx and yy to match the dimensions of box\n",
    "xx = xx[None, None, ...]\n",
    "yy = yy[None, None, ...]\n",
    "# print(xx.shape,yy.shape)\n",
    "\n",
    "# Check if the coordinates are inside the boxes\n",
    "masks = (xx >= box[..., 0, None, None]) & (xx <= box[..., 2, None, None]) & \\\n",
    "        (yy >= box[..., 1, None, None]) & (yy <= box[..., 3, None, None])\n",
    "\n",
    "# Combine the masks for different boxes using logical OR\n",
    "mask = masks.any(dim=1)\n",
    "\n",
    "# Set the value of x into 1 inside each bounding box region\n",
    "x[mask] = 1\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((2,4,2))\n",
    "new_points = torch.cat([a,a],dim=-1)\n",
    "print(new_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn((4,3))\n",
    "print(x)\n",
    "scores, labels = x.max(-1)\n",
    "print(scores,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "def generate_grid(height: int, width: int, z: int = 0):\n",
    "    xs = torch.linspace(0, 1, width)\n",
    "    ys = torch.linspace(0, 1, height)\n",
    "\n",
    "    if z > 0 :\n",
    "        zs = torch.linspace(0, 1, z)\n",
    "        indices = torch.stack(torch.meshgrid((xs, ys, zs),indexing='xy'), 0)   \n",
    "    else:\n",
    "        indices = torch.stack(torch.meshgrid((xs, ys), indexing='xy'), 0)       # 2 h w\n",
    "        indices = F.pad(indices, (0, 0, 0, 0, 0, 1), value=1)                   # 3 h w\n",
    "    indices = indices[None]                                                 # 1 3 h w\n",
    "\n",
    "    return indices\n",
    "\n",
    "def positionalencoding2d(d_model, height, width, V):\n",
    "    \"\"\"\n",
    "    :param d_model: dimension of the model\n",
    "    :param height: height of the positions\n",
    "    :param width: width of the positions\n",
    "    :return: d_model*height*width position matrix\n",
    "    \"\"\"\n",
    "    V_inv = torch.FloatTensor(V).inverse()\n",
    "    pos = generate_grid(height, width)[0]\n",
    "    pos[0] = 200 * pos[0]\n",
    "    pos[1] = 200 * pos[1]\n",
    "    pos = V_inv @ pos.reshape(3, height * width)\n",
    "    pos = pos.reshape(3,height, width)[:2]\n",
    "    pos_h, pos_w = pos[0,:,0].unsqueeze(1), pos[1,0,:].unsqueeze(1)\n",
    "    print(pos_h)\n",
    "    if d_model % 4 != 0:\n",
    "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
    "    pe = torch.zeros(d_model, height, width)\n",
    "    # Each dimension use half of d_model\n",
    "    d_model = int(d_model / 2)\n",
    "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                         -(math.log(10000.0) / d_model)).unsqueeze(0)\n",
    "    pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    return pe\n",
    "\n",
    "pe = positionalencoding2d(128, 25, 25, l[0]['view'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 2126813\n",
    "fn = 1615751\n",
    "tp = 30084\n",
    "fn = 85496\n",
    "tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize the array a and the index array b\n",
    "a = np.zeros((10,6))\n",
    "z_stats = [\n",
    "            [0.9496, 1.7372], # car\n",
    "            [1.5563, 2.8328], # truck\n",
    "            [1.8626, 3.5100], # bus\n",
    "            [2.1127, 3.8164], # trailer\n",
    "            [1.3749, 2.5279], # construction\n",
    "            [1.0667, 1.7676], # pedestrian\n",
    "            [0.8392, 1.4717], # motorcycle\n",
    "            [0.7497, 1.3034], # bicycle\n",
    "        ]\n",
    "b = np.random.randint(len(z_stats), size=10)\n",
    "\n",
    "# Vectorize the assigning operation\n",
    "a[:, 4] = np.array(z_stats)[b, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand((4,100,6,3)) # b q p 3\n",
    "b = torch.rand((4,100,3)) # b q 3\n",
    "c = a + b.unsqueeze(2)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 25, 25\n",
    "bs = 2\n",
    "ref_y, ref_x = torch.meshgrid(\n",
    "                torch.linspace(\n",
    "                    0.5, H - 0.5, H),\n",
    "                torch.linspace(\n",
    "                    0.5, W - 0.5, W)\n",
    "            )\n",
    "ref_y = ref_y.reshape(-1)[None] / H\n",
    "ref_x = ref_x.reshape(-1)[None] / W\n",
    "ref_2d = torch.stack((ref_x, ref_y), -1)\n",
    "ref_2d = ref_2d.repeat(bs, 1, 1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# pred_boxes: BxNx6\n",
    "# coords = pred_boxes[..., :2] # pad 1 B N 3\n",
    "b, N = 4, 100\n",
    "\n",
    "pred_boxes_coords = torch.rand((b,N,2))\n",
    "pred_logits = torch.rand((b,N,8))\n",
    "box_feats = torch.rand((b,N,128))\n",
    "view = torch.rand((b,3,3))\n",
    "\n",
    "scores, _ = pred_logits.softmax(-1)[..., :-1].max(-1)\n",
    "filter_idx = torch.topk(scores, k=50, dim=-1).indices\n",
    "# Expand dimensions for filter_idx for matching with pred_boxes_coords\n",
    "filter_idx_expand = filter_idx.unsqueeze(-1).expand(*filter_idx.shape, pred_boxes_coords.shape[-1])\n",
    "\n",
    "# Use torch.gather to index pred_boxes_coords with filter_idx\n",
    "pred_boxes_coords = torch.gather(pred_boxes_coords, 1, filter_idx_expand)\n",
    "\n",
    "filter_idx_expand = filter_idx.unsqueeze(-1).expand(*filter_idx.shape, 128)\n",
    "box_feats = torch.gather(box_feats, 1, filter_idx_expand)\n",
    "\n",
    "pred_boxes_coords = torch.nn.functional.pad(pred_boxes_coords,(0, 1), value=1) # b filter_N 3\n",
    "pred_boxes_coords = ((torch.einsum('b i j, b N j -> b N i', view, pred_boxes_coords)[..., :2])* 100).int()\n",
    "\n",
    "batch_idx = torch.arange(0, b).view(-1,1,1).expand(-1,50,1).int()\n",
    "pred_boxes_coords = torch.cat([batch_idx, pred_boxes_coords], dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseConvTensor[shape=torch.Size([200, 128])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spconv.pytorch as spconv\n",
    "\n",
    "spconv.SparseConvTensor(box_feats.flatten(0,1), pred_boxes_coords.flatten(0,1), [200,200], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([122, 144], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_boxes_coords.flatten(0,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "B, H, W = 2, 10, 10\n",
    "mask = torch.zeros([B,H,W])\n",
    "# b = torch.arange(B)[:, None].to(device)\n",
    "# mask[b, pred_boxes_coords[..., 1], pred_boxes_coords[..., 0]] = 1\n",
    "mask[0, 2,3] = 1\n",
    "mask[1, 1,1] = 1\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "mask = mask.unsqueeze(1)\n",
    "\n",
    "patch_size = 3\n",
    "kernel = torch.ones(\n",
    "    (1, 1, patch_size, patch_size), dtype=torch.float64\n",
    ")\n",
    "augm_mask = torch.nn.functional.conv2d(\n",
    "    mask.to(torch.float64), kernel, padding=(patch_size - 1) // 2\n",
    ")\n",
    "augm_mask = augm_mask.bool().squeeze(1)\n",
    "print(augm_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_idx_to_keep(mask, N_pts):\n",
    "    \"\"\"Select final points to keep.\n",
    "    Either we keep Nfine points ordered by their importance or we reinject random points when points are\n",
    "    predicted as not important, otherwise we will have an artefact at the bottom due to the selection\n",
    "    on uniform null points.\n",
    "    \"\"\"\n",
    "    # Alias\n",
    "    bt = mask.size(0)\n",
    "    device = mask.device\n",
    "\n",
    "    out_idx = []\n",
    "    if N_pts == \"dyna\":\n",
    "        for i in range(bt):\n",
    "            # Numbers of activated elements\n",
    "            activ_idx = torch.nonzero(mask[i]).squeeze(1)\n",
    "            out_idx.append(activ_idx)\n",
    "    else:\n",
    "        # Reinject random points in batches\n",
    "        for i in range(bt):\n",
    "            # Numbers of activated elements\n",
    "            activ_idx = torch.nonzero(mask[i]).squeeze(1)\n",
    "            # How many points are not activated.\n",
    "            n_activ = activ_idx.size(0)\n",
    "            idle = N_pts - n_activ\n",
    "\n",
    "            # Less detected points than N_pts\n",
    "            if idle > 0:\n",
    "                # Random selection\n",
    "                allowed_idx = torch.nonzero(mask[i] == 0).squeeze(1)\n",
    "                perm = torch.randperm(allowed_idx.size(0))\n",
    "                augm_idx = allowed_idx[perm[:idle]]\n",
    "            else:\n",
    "                augm_idx = torch.empty([0], device=device, dtype=torch.int64)\n",
    "                activ_idx = activ_idx[:N_pts]\n",
    "\n",
    "            out_idx.append(torch.cat([activ_idx, augm_idx]))\n",
    "\n",
    "    out_idx = torch.stack(out_idx)\n",
    "    # xy_vox_idx = torch.stack([((out_idx // Y) % X), out_idx % Y], dim=-1)\n",
    "    return out_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_4d_tensor(X, Y):\n",
    "    B, N, _ = Y.shape\n",
    "    b = torch.arange(B)[:, None].expand(-1, N)  # Create a tensor for batch indices\n",
    "    h, w = Y.unbind(dim=-1)  # Split the last dimension of Y into separate tensors\n",
    "    indexed_X = X[b, h, w]  # Use advanced indexing to index X\n",
    "\n",
    "    return indexed_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 10])\n",
      "torch.Size([2, 5, 2])\n",
      "torch.Size([2, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "def _init_bev_layers(H=25, W=25, Z=8, num_points_in_pillar=4, **kwargs):\n",
    "    # zs = torch.linspace(0.5, Z - 0.5, num_points_in_pillar\n",
    "    #                         ).view(-1, 1, 1).expand(num_points_in_pillar, H, W) / Z\n",
    "    xs = torch.linspace(0.5, W - 0.5, W\n",
    "                        ).view(1, W).expand(H, W) / W\n",
    "    ys = torch.linspace(0.5, H - 0.5, H\n",
    "                        ).view(H, 1).expand(H, W) / H\n",
    "    ref_3d = torch.stack((xs, ys), -1)\n",
    "    return ref_3d\n",
    "\n",
    "grid = _init_bev_layers(H,W)[None].expand(2,-1,-1,-1)\n",
    "\n",
    "print(augm_mask.shape)\n",
    "print(_select_idx_to_keep(augm_mask, 5).shape)\n",
    "selected_grid = index_4d_tensor(grid, _select_idx_to_keep(augm_mask, 5))\n",
    "print(selected_grid.shape) # b n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5, 1]) torch.Size([2, 4, 5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange, repeat\n",
    "num_points_in_pillar = 4\n",
    "N = 5\n",
    "zs = torch.linspace(0.5, 8 - 0.5, num_points_in_pillar\n",
    "                                ).view(-1, 1).expand(num_points_in_pillar, N) / 8\n",
    "pad_zs = repeat(zs, 'p n -> b p n 1', b=B)\n",
    "selected_grid = repeat(selected_grid, 'b n d -> b p n d', p=num_points_in_pillar)\n",
    "print(pad_zs.shape,selected_grid.shape)\n",
    "torch.cat([selected_grid, pad_zs],dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5, 1]) torch.Size([2, 4, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(pad_zs.shape,selected_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
